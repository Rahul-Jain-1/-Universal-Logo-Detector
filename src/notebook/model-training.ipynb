{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:03:25.035766Z",
     "iopub.status.busy": "2025-05-27T13:03:25.035580Z",
     "iopub.status.idle": "2025-05-27T13:03:25.040212Z",
     "shell.execute_reply": "2025-05-27T13:03:25.039425Z",
     "shell.execute_reply.started": "2025-05-27T13:03:25.035749Z"
    },
    "id": "MpDzhLyjo6mP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from lxml import etree as ET\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Rt Detr V2 image processor and pretrained model from hugging face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "19db15cbe36e4f6983d52c572e94b29c",
      "afe4e6215fa541218db50b6a8c1aca82",
      "2eda47164bcd4aaaaec3f5ada927be06",
      "7f100bf8cbc14635b0960e08dbee111c",
      "f6b4b9314feb4fb18861d60e037f9edf",
      "985c201e73a94890a8dae7650937acc5",
      "8e980a665aeb46b0a643fc618c7e4781",
      "3b23ab87600b45c2a6cab506dbeca5bf",
      "5a03aa472df246469d8327ca7e4e7c0f",
      "9d901617998043e0a96f382d28268133",
      "5dd99c76deb048be99e972d8552e8f54"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-05-27T13:03:50.342790Z",
     "iopub.status.busy": "2025-05-27T13:03:50.342505Z",
     "iopub.status.idle": "2025-05-27T13:03:50.447098Z",
     "shell.execute_reply": "2025-05-27T13:03:50.446541Z",
     "shell.execute_reply.started": "2025-05-27T13:03:50.342768Z"
    },
    "id": "iHg4d6ekpEH9",
    "outputId": "51d30079-4781-4e9f-d8ce-8df915125b18",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoImageProcessor\n",
    "checkpoint = \"PekingU/rtdetr_v2_r50vd\"\n",
    "image_size = 480\n",
    "\n",
    "# set image to 480 x480\n",
    "image_processor = AutoImageProcessor.from_pretrained(\n",
    "    checkpoint,\n",
    "    do_resize=True,\n",
    "    size={\"width\": image_size, \"height\": image_size},\n",
    "    use_fast=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-27T13:03:52.035953Z",
     "iopub.status.busy": "2025-05-27T13:03:52.035358Z",
     "iopub.status.idle": "2025-05-27T13:03:52.385344Z",
     "shell.execute_reply": "2025-05-27T13:03:52.384636Z",
     "shell.execute_reply.started": "2025-05-27T13:03:52.035931Z"
    },
    "id": "l8zhAkWhpKVA",
    "outputId": "79f6c317-018d-421f-ee1b-d794d174655f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "\n",
    "train_augmentation_and_transform = A.Compose(\n",
    "    [\n",
    "        A.Perspective(p=0.1),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.HueSaturationValue(p=0.1),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"category\"], clip=True, min_area=25, min_width=1, min_height=1),\n",
    ")\n",
    "\n",
    "# to make sure boxes are clipped to image size and there is no boxes with area < 1 pixel\n",
    "validation_transform = A.Compose(\n",
    "    [A.NoOp()],\n",
    "    bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"category\"], clip=True, min_area=1, min_width=1, min_height=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-05-27T13:03:59.032909Z",
     "iopub.status.busy": "2025-05-27T13:03:59.032232Z",
     "iopub.status.idle": "2025-05-27T13:04:00.376898Z",
     "shell.execute_reply": "2025-05-27T13:04:00.376148Z",
     "shell.execute_reply.started": "2025-05-27T13:03:59.032886Z"
    },
    "id": "wWx2i8swpMYo",
    "outputId": "3d9e8b59-2d88-42e4-dca0-89b2f2232969",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RTDetrV2ForObjectDetection were not initialized from the model checkpoint at PekingU/rtdetr_v2_r50vd and are newly initialized because the shapes did not match:\n",
      "- model.decoder.class_embed.0.bias: found shape torch.Size([80]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- model.decoder.class_embed.0.weight: found shape torch.Size([80, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated\n",
      "- model.decoder.class_embed.1.bias: found shape torch.Size([80]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- model.decoder.class_embed.1.weight: found shape torch.Size([80, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated\n",
      "- model.decoder.class_embed.2.bias: found shape torch.Size([80]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- model.decoder.class_embed.2.weight: found shape torch.Size([80, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated\n",
      "- model.decoder.class_embed.3.bias: found shape torch.Size([80]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- model.decoder.class_embed.3.weight: found shape torch.Size([80, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated\n",
      "- model.decoder.class_embed.4.bias: found shape torch.Size([80]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- model.decoder.class_embed.4.weight: found shape torch.Size([80, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated\n",
      "- model.decoder.class_embed.5.bias: found shape torch.Size([80]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- model.decoder.class_embed.5.weight: found shape torch.Size([80, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated\n",
      "- model.denoising_class_embed.weight: found shape torch.Size([81, 256]) in the checkpoint and torch.Size([2, 256]) in the model instantiated\n",
      "- model.enc_score_head.bias: found shape torch.Size([80]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "- model.enc_score_head.weight: found shape torch.Size([80, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RTDetrV2ForObjectDetection(\n",
       "  (model): RTDetrV2Model(\n",
       "    (backbone): RTDetrV2ConvEncoder(\n",
       "      (model): RTDetrResNetBackbone(\n",
       "        (embedder): RTDetrResNetEmbeddings(\n",
       "          (embedder): Sequential(\n",
       "            (0): RTDetrResNetConvLayer(\n",
       "              (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): RTDetrResNetConvLayer(\n",
       "              (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (2): RTDetrResNetConvLayer(\n",
       "              (convolution): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (encoder): RTDetrResNetEncoder(\n",
       "          (stages): ModuleList(\n",
       "            (0): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): RTDetrResNetShortCut(\n",
       "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Sequential(\n",
       "                    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                    (1): RTDetrResNetShortCut(\n",
       "                      (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                    )\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (3): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Sequential(\n",
       "                    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                    (1): RTDetrResNetShortCut(\n",
       "                      (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                    )\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (3): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (4): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (5): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Sequential(\n",
       "                    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                    (1): RTDetrResNetShortCut(\n",
       "                      (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                    )\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrV2FrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_input_proj): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder): RTDetrV2HybridEncoder(\n",
       "      (encoder): ModuleList(\n",
       "        (0): RTDetrV2Encoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): RTDetrV2EncoderLayer(\n",
       "              (self_attn): RTDetrV2MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lateral_convs): ModuleList(\n",
       "        (0-1): 2 x RTDetrV2ConvNormLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (fpn_blocks): ModuleList(\n",
       "        (0-1): 2 x RTDetrV2CSPRepLayer(\n",
       "          (conv1): RTDetrV2ConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (conv2): RTDetrV2ConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (bottlenecks): Sequential(\n",
       "            (0): RTDetrV2RepVggBlock(\n",
       "              (conv1): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (1): RTDetrV2RepVggBlock(\n",
       "              (conv1): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (2): RTDetrV2RepVggBlock(\n",
       "              (conv1): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (conv3): Identity()\n",
       "        )\n",
       "      )\n",
       "      (downsample_convs): ModuleList(\n",
       "        (0-1): 2 x RTDetrV2ConvNormLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (pan_blocks): ModuleList(\n",
       "        (0-1): 2 x RTDetrV2CSPRepLayer(\n",
       "          (conv1): RTDetrV2ConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (conv2): RTDetrV2ConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (bottlenecks): Sequential(\n",
       "            (0): RTDetrV2RepVggBlock(\n",
       "              (conv1): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (1): RTDetrV2RepVggBlock(\n",
       "              (conv1): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (2): RTDetrV2RepVggBlock(\n",
       "              (conv1): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrV2ConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (conv3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (denoising_class_embed): Embedding(2, 256, padding_idx=1)\n",
       "    (enc_output): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_score_head): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (enc_bbox_head): RTDetrV2MLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder_input_proj): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): RTDetrV2Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x RTDetrV2DecoderLayer(\n",
       "          (self_attn): RTDetrV2MultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): RTDetrV2MultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (query_pos_head): RTDetrV2MLPPredictionHead(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=4, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (class_embed): ModuleList(\n",
       "        (0-5): 6 x Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "      (bbox_embed): ModuleList(\n",
       "        (0-5): 6 x RTDetrV2MLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (class_embed): ModuleList(\n",
       "    (0-5): 6 x Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (bbox_embed): ModuleList(\n",
       "    (0-5): 6 x RTDetrV2MLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForObjectDetection\n",
    "import torch\n",
    "classname2idx = {\"logo\": 0}\n",
    "idx2classname =  {0:\"logo\"}\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=idx2classname,\n",
    "    label2id=classname2idx,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:21.793733Z",
     "iopub.status.busy": "2025-05-27T13:04:21.792710Z",
     "iopub.status.idle": "2025-05-27T13:04:21.799860Z",
     "shell.execute_reply": "2025-05-27T13:04:21.799139Z",
     "shell.execute_reply.started": "2025-05-27T13:04:21.793705Z"
    },
    "id": "o2YlCAU-q7K_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class LogoDataset(Dataset):\n",
    "    def __init__(self, dataset, image_processor, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.image_processor = image_processor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "\n",
    "        image_path = sample[\"file_path\"]\n",
    "        image = Image.open(image_path)\n",
    "        formatted_annotations = sample[\"annotation\"]\n",
    "\n",
    "        # Convert image to RGB numpy array\n",
    "        image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "        result = self.image_processor(\n",
    "            images=image, annotations=formatted_annotations, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Image processor expands batch dimension, lets squeeze it\n",
    "        result = {k: v[0] for k, v in result.items()}\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load transformed dataset from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:23.569183Z",
     "iopub.status.busy": "2025-05-27T13:04:23.568621Z",
     "iopub.status.idle": "2025-05-27T13:04:25.336635Z",
     "shell.execute_reply": "2025-05-27T13:04:25.335825Z",
     "shell.execute_reply.started": "2025-05-27T13:04:23.569161Z"
    },
    "id": "ixGE57L-pPuz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_path = \"/kaggle/input/dataset-logo/train_dataset.pkl\"\n",
    "valid_path = \"/kaggle/input/dataset-logo/validation_dataset.pkl\"\n",
    "\n",
    "with open(train_path, \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(valid_path, \"rb\") as f:\n",
    "    valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set training arguments, evualting model after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:27.030024Z",
     "iopub.status.busy": "2025-05-27T13:04:27.029724Z",
     "iopub.status.idle": "2025-05-27T13:04:27.573161Z",
     "shell.execute_reply": "2025-05-27T13:04:27.572553Z",
     "shell.execute_reply.started": "2025-05-27T13:04:27.030003Z"
    },
    "id": "pcsVe6uLpgb9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "# 1) Clear any stray allocations\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"rtdetr-v2-finetune-on-logo\",\n",
    "    num_train_epochs=5,\n",
    "    max_grad_norm=0.1,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=300,\n",
    "    per_device_train_batch_size=8,\n",
    "    dataloader_num_workers=2,\n",
    "    metric_for_best_model=\"eval_map\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    eval_do_concat_batches=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:30.851579Z",
     "iopub.status.busy": "2025-05-27T13:04:30.850660Z",
     "iopub.status.idle": "2025-05-27T13:04:30.856143Z",
     "shell.execute_reply": "2025-05-27T13:04:30.855380Z",
     "shell.execute_reply.started": "2025-05-27T13:04:30.851538Z"
    },
    "id": "bcyAgL8arMHy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data = {}\n",
    "    data[\"pixel_values\"] = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "    data[\"labels\"] = [x[\"labels\"] for x in batch]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create custom MapEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:32.539481Z",
     "iopub.status.busy": "2025-05-27T13:04:32.538842Z",
     "iopub.status.idle": "2025-05-27T13:04:32.676245Z",
     "shell.execute_reply": "2025-05-27T13:04:32.675644Z",
     "shell.execute_reply.started": "2025-05-27T13:04:32.539454Z"
    },
    "id": "c_ge_vXNrUKI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from transformers.image_transforms import center_to_corners_format\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelOutput:\n",
    "    logits: torch.Tensor\n",
    "    pred_boxes: torch.Tensor\n",
    "\n",
    "\n",
    "class MAPEvaluator:\n",
    "\n",
    "    def __init__(self, image_processor, threshold=0.00, id2label=None):\n",
    "        self.image_processor = image_processor\n",
    "        self.threshold = threshold\n",
    "        self.id2label = id2label\n",
    "\n",
    "    def collect_image_sizes(self, targets):\n",
    "        \"\"\"Collect image sizes across the dataset as list of tensors with shape [batch_size, 2].\"\"\"\n",
    "        image_sizes = []\n",
    "        for batch in targets:\n",
    "            batch_image_sizes = torch.tensor(np.array([x[\"size\"] for x in batch]))\n",
    "            image_sizes.append(batch_image_sizes)\n",
    "        return image_sizes\n",
    "\n",
    "    def collect_targets(self, targets, image_sizes):\n",
    "        post_processed_targets = []\n",
    "        for target_batch, image_size_batch in zip(targets, image_sizes):\n",
    "            for target, size in zip(target_batch, image_size_batch):\n",
    "\n",
    "                # here we have \"yolo\" format (x_center, y_center, width, height) in relative coordinates 0..1\n",
    "                # and we need to convert it to \"pascal\" format (x_min, y_min, x_max, y_max) in absolute coordinates\n",
    "                height, width = size\n",
    "                boxes = torch.tensor(target[\"boxes\"])\n",
    "                boxes = center_to_corners_format(boxes)\n",
    "                boxes = boxes * torch.tensor([[width, height, width, height]])\n",
    "\n",
    "                labels = torch.tensor(target[\"class_labels\"])\n",
    "                post_processed_targets.append({\"boxes\": boxes, \"labels\": labels})\n",
    "        return post_processed_targets\n",
    "\n",
    "    def collect_predictions(self, predictions, image_sizes):\n",
    "        post_processed_predictions = []\n",
    "        for batch, target_sizes in zip(predictions, image_sizes):\n",
    "            batch_logits, batch_boxes = batch[1], batch[2]\n",
    "            output = ModelOutput(logits=torch.tensor(batch_logits), pred_boxes=torch.tensor(batch_boxes))\n",
    "            post_processed_output = self.image_processor.post_process_object_detection(\n",
    "                output, threshold=self.threshold, target_sizes=target_sizes\n",
    "            )\n",
    "            post_processed_predictions.extend(post_processed_output)\n",
    "        return post_processed_predictions\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, evaluation_results):\n",
    "        # 1) Pre- and post-process your preds & targets\n",
    "        predictions, targets = evaluation_results.predictions, evaluation_results.label_ids\n",
    "\n",
    "        image_sizes = self.collect_image_sizes(targets)\n",
    "        post_processed_targets = self.collect_targets(targets, image_sizes)\n",
    "        post_processed_predictions = self.collect_predictions(predictions, image_sizes)\n",
    "    \n",
    "        # 2) Instantiate the metric under the name \"evaluator\"\n",
    "        evaluator = MeanAveragePrecision(box_format=\"xyxy\", class_metrics=True)\n",
    "        evaluator.warn_on_many_detections = False\n",
    "        evaluator.update(post_processed_predictions, post_processed_targets)\n",
    "\n",
    "        metrics = evaluator.compute()\n",
    "    \n",
    "        # then your wrapping of per-class metrics, rounding, etc\n",
    "        return metrics\n",
    "\n",
    "\n",
    "eval_compute_metrics_fn = MAPEvaluator(image_processor=image_processor, threshold=0.01, id2label=idx2classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:35.837562Z",
     "iopub.status.busy": "2025-05-27T13:04:35.836382Z",
     "iopub.status.idle": "2025-05-27T13:04:35.840878Z",
     "shell.execute_reply": "2025-05-27T13:04:35.840288Z",
     "shell.execute_reply.started": "2025-05-27T13:04:35.837536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:36.099789Z",
     "iopub.status.busy": "2025-05-27T13:04:36.099480Z",
     "iopub.status.idle": "2025-05-27T13:04:36.104239Z",
     "shell.execute_reply": "2025-05-27T13:04:36.103517Z",
     "shell.execute_reply.started": "2025-05-27T13:04:36.099767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import logging as hf_logging\n",
    "\n",
    "# suppress everything below ERROR\n",
    "hf_logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take 5% subset of whole dataset from both train and valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:41.219380Z",
     "iopub.status.busy": "2025-05-27T13:04:41.218640Z",
     "iopub.status.idle": "2025-05-27T13:04:41.266057Z",
     "shell.execute_reply": "2025-05-27T13:04:41.265330Z",
     "shell.execute_reply.started": "2025-05-27T13:04:41.219340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9922, 0.9922, 0.9922],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9922, 0.9922, 0.9922],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9922, 0.9922, 0.9922]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]),\n",
       " 'labels': {'size': tensor([480, 480]), 'image_id': tensor([15440]), 'class_labels': tensor([0, 0, 0]), 'boxes': tensor([[0.1956, 0.6481, 0.2331, 0.2937],\n",
       "         [0.4981, 0.6759, 0.1715, 0.3544],\n",
       "         [0.8112, 0.6772, 0.1618, 0.3519]]), 'area': tensor([15774.7100, 14003.4824, 13122.3652]), 'iscrowd': tensor([0, 0, 0]), 'orig_size': tensor([395, 519])}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking first 5% records only  from train dataset\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# 1. compute split sizes\n",
    "total = len(train)\n",
    "n_small = int(0.05 * total)\n",
    "n_rest  = total - n_small\n",
    "\n",
    "# 2. do the random split (with a fixed seed for reproducibility)\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "small_train_ds, _ = random_split(\n",
    "    train,\n",
    "    [n_small, n_rest],\n",
    "    generator=generator\n",
    ")\n",
    "print(len(small_train_ds))\n",
    "small_train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:41.397976Z",
     "iopub.status.busy": "2025-05-27T13:04:41.397682Z",
     "iopub.status.idle": "2025-05-27T13:04:41.421098Z",
     "shell.execute_reply": "2025-05-27T13:04:41.420421Z",
     "shell.execute_reply.started": "2025-05-27T13:04:41.397952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 480, 480])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking first 5% records only  from valid dataset\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# 1. compute split sizes\n",
    "valid_total = len(valid)\n",
    "n_small_valid = int(0.05 * valid_total)\n",
    "n_rest_valid  = valid_total - n_small_valid\n",
    "\n",
    "# 2. do the random split (with a fixed seed for reproducibility)\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "small_valid_ds, _ = random_split(\n",
    "    valid,\n",
    "    [n_small_valid, n_rest_valid],\n",
    "    generator=generator\n",
    ")\n",
    "print(len(small_valid_ds))\n",
    "small_valid_ds[0][\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:43.684110Z",
     "iopub.status.busy": "2025-05-27T13:04:43.683365Z",
     "iopub.status.idle": "2025-05-27T13:04:45.275199Z",
     "shell.execute_reply": "2025-05-27T13:04:45.274559Z",
     "shell.execute_reply.started": "2025-05-27T13:04:43.684052Z"
    },
    "id": "3d1V4X2ypg_x",
    "outputId": "76e9a852-26cb-4953-808b-021d67ca8355",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_421/974300604.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_ds,\n",
    "    eval_dataset=small_valid_ds,\n",
    "    tokenizer=image_processor,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=eval_compute_metrics_fn,\n",
    ")\n",
    "print(\"start\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T13:04:47.023229Z",
     "iopub.status.busy": "2025-05-27T13:04:47.022539Z",
     "iopub.status.idle": "2025-05-27T13:51:26.552226Z",
     "shell.execute_reply": "2025-05-27T13:51:26.551477Z",
     "shell.execute_reply.started": "2025-05-27T13:04:47.023204Z"
    },
    "id": "oS_xVSOWrhvA",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjainshabrahul\u001b[0m (\u001b[33mrahuljain\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250527_130454-4dy0rq6y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rahuljain/huggingface/runs/4dy0rq6y' target=\"_blank\">rtdetr-v2-finetune-on-logo</a></strong> to <a href='https://wandb.ai/rahuljain/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rahuljain/huggingface' target=\"_blank\">https://wandb.ai/rahuljain/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rahuljain/huggingface/runs/4dy0rq6y' target=\"_blank\">https://wandb.ai/rahuljain/huggingface/runs/4dy0rq6y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3970' max='3970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3970/3970 46:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map</th>\n",
       "      <th>Map 50</th>\n",
       "      <th>Map 75</th>\n",
       "      <th>Map Small</th>\n",
       "      <th>Map Medium</th>\n",
       "      <th>Map Large</th>\n",
       "      <th>Mar 1</th>\n",
       "      <th>Mar 10</th>\n",
       "      <th>Mar 100</th>\n",
       "      <th>Mar Small</th>\n",
       "      <th>Mar Medium</th>\n",
       "      <th>Mar Large</th>\n",
       "      <th>Map Per Class</th>\n",
       "      <th>Mar 100 Per Class</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>75.104100</td>\n",
       "      <td>16.517601</td>\n",
       "      <td>0.098620</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.091947</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.060296</td>\n",
       "      <td>0.154176</td>\n",
       "      <td>0.207440</td>\n",
       "      <td>0.574350</td>\n",
       "      <td>0.743444</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.613830</td>\n",
       "      <td>0.792817</td>\n",
       "      <td>0.098620</td>\n",
       "      <td>0.743444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.746900</td>\n",
       "      <td>15.840319</td>\n",
       "      <td>0.154669</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.152305</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.087499</td>\n",
       "      <td>0.187939</td>\n",
       "      <td>0.246722</td>\n",
       "      <td>0.611498</td>\n",
       "      <td>0.747086</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.591702</td>\n",
       "      <td>0.804603</td>\n",
       "      <td>0.154669</td>\n",
       "      <td>0.747086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.780300</td>\n",
       "      <td>15.529080</td>\n",
       "      <td>0.191681</td>\n",
       "      <td>0.348199</td>\n",
       "      <td>0.186753</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.091824</td>\n",
       "      <td>0.256377</td>\n",
       "      <td>0.280749</td>\n",
       "      <td>0.631478</td>\n",
       "      <td>0.763944</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.642553</td>\n",
       "      <td>0.809693</td>\n",
       "      <td>0.191681</td>\n",
       "      <td>0.763944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12.636700</td>\n",
       "      <td>15.292116</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.294740</td>\n",
       "      <td>0.151084</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>0.208770</td>\n",
       "      <td>0.256816</td>\n",
       "      <td>0.628980</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.628085</td>\n",
       "      <td>0.814086</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>12.060000</td>\n",
       "      <td>15.252739</td>\n",
       "      <td>0.166947</td>\n",
       "      <td>0.309448</td>\n",
       "      <td>0.158867</td>\n",
       "      <td>0.028637</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.228708</td>\n",
       "      <td>0.275130</td>\n",
       "      <td>0.632362</td>\n",
       "      <td>0.769771</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.650426</td>\n",
       "      <td>0.815411</td>\n",
       "      <td>0.166947</td>\n",
       "      <td>0.769771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3970, training_loss=21.25415850814704, metrics={'train_runtime': 2798.6307, 'train_samples_per_second': 11.338, 'train_steps_per_second': 1.419, 'total_flos': 5.62267331875584e+18, 'train_loss': 21.25415850814704, 'epoch': 5.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T14:09:34.851989Z",
     "iopub.status.busy": "2025-05-27T14:09:34.851483Z",
     "iopub.status.idle": "2025-05-27T14:09:35.145266Z",
     "shell.execute_reply": "2025-05-27T14:09:35.144662Z",
     "shell.execute_reply.started": "2025-05-27T14:09:34.851968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"/kaggle/working/final_model\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T14:10:33.172597Z",
     "iopub.status.busy": "2025-05-27T14:10:33.171832Z",
     "iopub.status.idle": "2025-05-27T14:10:41.842821Z",
     "shell.execute_reply": "2025-05-27T14:10:41.842240Z",
     "shell.execute_reply.started": "2025-05-27T14:10:33.172574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Click here to download: <a href='/kaggle/working/rtdetr-v2-finetuned-model.zip' target='_blank'>/kaggle/working/rtdetr-v2-finetuned-model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/rtdetr-v2-finetuned-model.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "# 1) Set these paths:\n",
    "src_folder   = \"/kaggle/working/final_model\"            # <-- the folder you want to download\n",
    "archive_base = \"/kaggle/working/rtdetr-v2-finetuned-model\"    # <-- zip will be created at this path + \".zip\"\n",
    "\n",
    "# 2) Create the ZIP\n",
    "shutil.make_archive(archive_base, 'zip', src_folder)\n",
    "\n",
    "# 3) Display a download link\n",
    "zip_path = archive_base + \".zip\"\n",
    "display(FileLink(zip_path, result_html_prefix=\"Click here to download: \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 888440,
     "sourceId": 1508223,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7526769,
     "sourceId": 11969551,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "19db15cbe36e4f6983d52c572e94b29c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_afe4e6215fa541218db50b6a8c1aca82",
       "IPY_MODEL_2eda47164bcd4aaaaec3f5ada927be06",
       "IPY_MODEL_7f100bf8cbc14635b0960e08dbee111c"
      ],
      "layout": "IPY_MODEL_f6b4b9314feb4fb18861d60e037f9edf"
     }
    },
    "2eda47164bcd4aaaaec3f5ada927be06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b23ab87600b45c2a6cab506dbeca5bf",
      "max": 444,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a03aa472df246469d8327ca7e4e7c0f",
      "value": 444
     }
    },
    "3b23ab87600b45c2a6cab506dbeca5bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a03aa472df246469d8327ca7e4e7c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5dd99c76deb048be99e972d8552e8f54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f100bf8cbc14635b0960e08dbee111c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d901617998043e0a96f382d28268133",
      "placeholder": "",
      "style": "IPY_MODEL_5dd99c76deb048be99e972d8552e8f54",
      "value": "444/444[00:00&lt;00:00,47.8kB/s]"
     }
    },
    "8e980a665aeb46b0a643fc618c7e4781": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "985c201e73a94890a8dae7650937acc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d901617998043e0a96f382d28268133": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afe4e6215fa541218db50b6a8c1aca82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_985c201e73a94890a8dae7650937acc5",
      "placeholder": "",
      "style": "IPY_MODEL_8e980a665aeb46b0a643fc618c7e4781",
      "value": "preprocessor_config.json:100%"
     }
    },
    "f6b4b9314feb4fb18861d60e037f9edf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
